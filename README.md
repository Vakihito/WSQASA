# Weak supervision for sentiment analysis (WSQASA)


In this repository you will find the scripts we used to develop the WSQASA method and a sample notebook of the finetuned model.


## Astract
---

The growth of social networks, e-commerce, and journalistic media has resulted in the proliferation of opinions on various topics. Companies and government agencies are interested in understanding their customers' opinions about their products and services. Automatic sentiment analysis methods can be used to extract the general sentiment about a product. However, traditional sentiment analysis methods are inflexible in dealing with human queries, which tend to ask questions. Therefore, question-and-answer (QA) systems for sentiment analysis offer a promising alternative. This paper proposes a new method called Weak Supervision for Question and Answering Sentiment Analysis (WSQASA) that finetunes and extracts sentiment through QA models in an unsupervised manner. We investigate question-generation models associated with sentiment filters for weak supervision, generating domain-specific question-and-answer pairs for finetuning the QA model. Our method enables the generation of domain-specific question-and-answer pairs for finetuning the QA model, which significantly enhances the QA-based sentiment analysis results, even without the usage of labeled data.

## WSQASA - pipeline
![Proposal](/images/WSQASA_pipe.png)

<p>The illustrative figure of the pipeline of the WSQASA method on the left side shows the weak supervision process composed of a set of datasets, from which we split for the establishment of a synthetic database generated by a QG model. At the center is a filtering process of questions and answers, which is carried out through a sentiment model and a correlation between the synthetic answers and a dataset of issues. Finally, the last block defines the process of tuning the QA model, comparing it to the same untrained model on the test database.</p>

## Results
![Proposal](/images/f1_comp.png)

<p>Comparison chart of the different approaches to the WSQASA, the radius of the bubbles represents the size of the test dataset, while the axis <i>y</i> presents the relative gain of <i>F1</i>, the axis <i>x</i> represents the datasets under analysis and the colors of the bubbles represent the experiments carried out.</p>

## Files 

```bash
.
├── data
│   ├── LID_all_issues.csv      - LID data with all the issues
│   ├── train_data.pkl          - Train data synthetic dataset create from the QG process over all the datasets
│   ├── tweet_qa_train_form.pkl - contexts of the train data from the tweet_qa
│   ├── tweet_qa_train_QG_data.pkl      - synthetic data create via the QG process
│   └── tweet_qa_validation_form.pkl    - validatio/test data 
├── images 
│   ├── f1_comp.png
│   └── WSQASA_pipe.png
├── notebooks
│   ├── create_synthetic_dataset
│   │   ├── Generate artificial dataset.ipynb   - Notebook to use the QG pipeline
│   │   ├── poetry.lock                         - poetry dependencies to run this notebook
│   │   └── pyproject.toml                      
│   ├── Samples of the trained model.ipynb      - Notebook to test a model finetuned via WSQASA, should be uploaded to google collab 
│   └── WSQASA tweet_qa.ipynb                   - Notebook to run the WSQASA pipeline should be uploaded to google collab 
├── README.md
├── requirements.txt
└── scripts - WSQASA scripts
    ├── 2_1_similarity_search_answer_test_df.py
    ├── 2_similarity_search_answers_artificial_df.py
    ├── 3_training_the_qa_model_on_syntatic_data.py
    ├── 4_1_run_not_finetuned_model_over_dataset_with_specific_domain.py
    ├── 4_run_model_over_dataset_with_specific_domain.py
    ├── 5_compare_performance_of_models.py
    └── pipe.zip
```

## How to run the scripts
---
### 1. Running the WSQASA pipeline

To run the WSQASA pipeline, upload the `WSQASA tweet_qa.ipynb` notebook to google collab, then run the notebook. This will run the WSQASA pipeline with the parameters set in the notebook.

### 2. A simple test of a finetuned WSQASA model

To test a WSQASA finetuned model, just upload the `Samples of the trained model.ipynb` notebook to google colab, or click here [![Open All Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/18UAi02C9vEo0fMiMEcjnQc-GNfFYyoXa?usp=share_link)

### 3. To create synthetic datasets


Open the `WSQASA/notebooks/create_synthetic_dataset` and install the dependencies via poetry:

```shell
poetry install  
```

Then you may run the `Generate artificial dataset.ipynb`, this notebook will create a synthetic dataset based on the `tweet_qa_train_from.pkl` data. Please remember that you have to create a kernel to run this notebook.
